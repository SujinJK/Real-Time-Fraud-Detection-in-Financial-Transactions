{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Fraud Detection in Financial Transactions\n",
    "\n",
    "This project demonstrates the use of machine learning to detect fraudulent financial transactions. The model was trained on synthetic data, simulating real-world transaction patterns and fraud behavior. \n",
    "\n",
    "## Key Components:\n",
    "- **Synthetic Data Generation**: Created transaction data with attributes like transaction amount, user ID, and fraud labels.\n",
    "- **Feature Engineering**: Extracted key features like transaction time and transaction amount to improve model predictions.\n",
    "- **Model Training**: Random Forest classifier was used to detect fraudulent transactions.\n",
    "- **Real-Time Simulation**: The model was tested in a simulated real-time environment for predicting fraud on incoming transactions.\n",
    "\n",
    "This project can be expanded by incorporating real-world datasets and improving the modelâ€™s generalization for use in live systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from faker import Faker\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2  feature_3  feature_4  feature_5 transaction_id  \\\n",
      "0  -0.038769  -0.649239  -0.224746  -1.346275   0.126879       TX100000   \n",
      "1   1.005284  -1.373239   1.157346   0.126493   1.422799       TX100001   \n",
      "2  -0.742455  -0.573257   1.688442  -2.588237   0.762562       TX100002   \n",
      "3   2.440938  -2.556425  -0.930664   0.111514  -1.133170       TX100003   \n",
      "4  -0.941758   0.367913  -0.549360  -2.029919  -1.503957       TX100004   \n",
      "\n",
      "                                user_id  transaction_amount  \\\n",
      "0  90e78a02-a361-49fa-a062-68fea3a46031                5.80   \n",
      "1  0f3c6246-a8f6-462d-931e-028b2db60849               23.78   \n",
      "2  c905fbc7-f6d0-44d8-90fe-38d3cd9fbe4e               11.81   \n",
      "3  761aba91-acad-4311-acc9-7b75988d64ae                8.31   \n",
      "4  84d583ad-f77f-41d1-8926-1fa737f32c25               30.99   \n",
      "\n",
      "      transaction_time              location  \\\n",
      "0  2025-01-22 04:32:28            East Eddie   \n",
      "1  2025-01-07 11:05:23  East Kathleenborough   \n",
      "2  2025-01-26 05:32:41           Lozanoville   \n",
      "3  2025-01-02 10:24:17             New James   \n",
      "4  2025-01-16 05:20:13            West Megan   \n",
      "\n",
      "                            merchant_id  label  \n",
      "0  cc555ce6-ee06-40e7-b7ae-b25845b4dc0b      0  \n",
      "1  1a4a1faa-2208-40c7-bb40-b358532dd464      0  \n",
      "2  2eaa8e2e-91ac-4e2f-a4b8-deca0b36de03      0  \n",
      "3  06a3513b-7b2d-46ca-9aa3-d647535fadcc      0  \n",
      "4  a5b44456-bcdd-4310-977e-03c9516665c1      0  \n"
     ]
    }
   ],
   "source": [
    "# Initialize Faker for generating realistic data\n",
    "fake = Faker()\n",
    "\n",
    "# Function to generate synthetic financial transaction data\n",
    "def generate_synthetic_data(num_records=1000, fraud_percentage=0.05):\n",
    "    # Generate random transaction data\n",
    "    X, y = make_classification(n_samples=num_records, n_features=5, n_informative=3, n_redundant=1, \n",
    "                               n_classes=2, weights=[1 - fraud_percentage, fraud_percentage], flip_y=0.01, random_state=42)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(5)])\n",
    "    \n",
    "    # Adding some realistic columns for financial transactions\n",
    "    df['transaction_id'] = [f'TX{100000 + i}' for i in range(num_records)]\n",
    "    df['user_id'] = [fake.uuid4() for _ in range(num_records)]\n",
    "    df['transaction_amount'] = np.random.lognormal(mean=3, sigma=1, size=num_records).round(2)  # Lognormal for skewed amounts\n",
    "    df['transaction_time'] = [fake.date_time_this_year().strftime('%Y-%m-%d %H:%M:%S') for _ in range(num_records)]\n",
    "    df['location'] = [fake.city() for _ in range(num_records)]\n",
    "    df['merchant_id'] = [fake.uuid4() for _ in range(num_records)]\n",
    "    df['label'] = y  # Fraud label (0 or 1)\n",
    "    \n",
    "    # Introduce some fraud patterns:\n",
    "    # - Large transaction amounts (fraudulent behavior)\n",
    "    large_transaction_mask = (df['label'] == 1) & (df['transaction_amount'] < 500)\n",
    "    df.loc[large_transaction_mask, 'transaction_amount'] = np.random.uniform(1000, 10000, size=large_transaction_mask.sum())\n",
    "    \n",
    "    # - Unusual transaction times (fraudulent behavior)\n",
    "    late_night_mask = (df['label'] == 1) & (df['transaction_time'].apply(lambda x: int(x.split(' ')[1].split(':')[0]) in [2, 3, 4, 5]))\n",
    "    df.loc[late_night_mask, 'transaction_time'] = [fake.date_time_this_year().replace(hour=np.random.choice([2, 3, 4, 5])).strftime('%Y-%m-%d %H:%M:%S') for _ in range(late_night_mask.sum())]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate synthetic data with 1000 records and 5% fraud\n",
    "synthetic_data = generate_synthetic_data(num_records=1000, fraud_percentage=0.05)\n",
    "\n",
    "# Save the dataset as a CSV file\n",
    "synthetic_data.to_csv('synthetic_fraud_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the synthetic data\n",
    "print(synthetic_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (800, 8)\n",
      "Test data shape: (200, 8)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing and feature engineering\n",
    "def preprocess_data(df):\n",
    "    # Convert transaction_time to datetime and extract hour and day of the week\n",
    "    df['transaction_time'] = pd.to_datetime(df['transaction_time'])\n",
    "    df['hour'] = df['transaction_time'].dt.hour\n",
    "    df['day_of_week'] = df['transaction_time'].dt.dayofweek\n",
    "    \n",
    "    # Drop non-numeric columns such as user_id, merchant_id, transaction_id, transaction_time, and location\n",
    "    df.drop(columns=['transaction_id', 'merchant_id', 'user_id', 'transaction_time', 'location'], inplace=True)\n",
    "    \n",
    "    # Normalize the transaction_amount\n",
    "    scaler = StandardScaler()\n",
    "    df['transaction_amount'] = scaler.fit_transform(df[['transaction_amount']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "synthetic_data = preprocess_data(synthetic_data)\n",
    "\n",
    "# Split data into features and labels\n",
    "X = synthetic_data.drop(columns=['label'])\n",
    "y = synthetic_data['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the data after splitting\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Test data shape: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       190\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[190   0]\n",
      " [  0  10]]\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
